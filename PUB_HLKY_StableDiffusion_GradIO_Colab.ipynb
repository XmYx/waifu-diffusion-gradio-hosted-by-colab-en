{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XmYx/waifu-diffusion-gradio-hosted-by-colab-en/blob/main/PUB_HLKY_StableDiffusion_GradIO_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLTb-y0dr8Yu"
      },
      "source": [
        "#HLKY Stable Diffusion GradIO Host - Colab version - IMPORTANT - USE AN NGROK TUNNEL TO AVOID GUI FREEZE\n",
        "\n",
        "This is a Stable Diffusion that can be used from a browser, hosted on Colab. The work is done by HLKY.\n",
        "\n",
        "Get the weights (model) from Hugginface, to do that, you must first accept the Terms of Services at ComVis's Stable Diffusion main page:\n",
        "https://huggingface.co/CompVis/stable-diffusion\n",
        "Then download from here:\n",
        "https://huggingface.co/CompVis/stable-diffusion-v-1-4-original\n",
        "Rename it to 'model.ckpt' and place it on your Google Drive, no folder, just in the root. Ugly.\n",
        "Run all cells, they don't have to be expanded.\n",
        "\n",
        "You will find your public URL in the last one:\n",
        "\"Running on public URL: https://XXXX.gradio.app\" \n",
        "\n",
        "#Without ngrok (using the xxxxx.gradio.app address), jobs over 40 seconds will not show any output, but will be saved to Drive. It's a WebSocket error, ngrok tunnels their address to this Colab's localhost. You don't have to install anything locally to use ngrok, just go to their website, create a free account, and get your Token, and Endpoint (link to your instance).\n",
        "\n",
        "#All features listed on the original Githubs: https://github.com/hlky/stable-diffusion\n",
        "#https://github.com/deforum/stable-diffusion\n",
        "#https://github.com/Mimocro/waifu-diffusion-gradio-hosted-by-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Update HLKY Repo - Run this cell to update to the latest version of HLKY."
      ],
      "metadata": {
        "id": "08hxNX3b6Jy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/stable-diffusion\n",
        "!rm -r /content/stable-diffusion-webui\n",
        "%cd /content\n",
        "!git clone https://github.com/hlky/stable-diffusion\n",
        "!git clone https://github.com/hlky/stable-diffusion-webui\n",
        "!pip install -e /content/stable-diffusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiejAMr25L6e",
        "outputId": "204bf037-9143-433e-bb70-9c0b87b76d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stable-diffusion'...\n",
            "remote: Enumerating objects: 751, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 751 (delta 60), reused 78 (delta 52), pack-reused 646\u001b[K\n",
            "Receiving objects: 100% (751/751), 42.57 MiB | 15.36 MiB/s, done.\n",
            "Resolving deltas: 100% (346/346), done.\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 742, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 742 (delta 9), reused 15 (delta 8), pack-reused 724\u001b[K\n",
            "Receiving objects: 100% (742/742), 16.43 MiB | 20.93 MiB/s, done.\n",
            "Resolving deltas: 100% (427/427), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/stable-diffusion\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/site-packages (from latent-diffusion==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from latent-diffusion==0.0.1) (1.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from latent-diffusion==0.0.1) (4.64.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/site-packages (from torch->latent-diffusion==0.0.1) (4.3.0)\n",
            "Installing collected packages: latent-diffusion\n",
            "  Running setup.py develop for latent-diffusion\n",
            "Successfully installed latent-diffusion-0.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPORTANT, CREATE AN NGROK ACCOUNT, AND RUN BELOW CELL, THEN FIND YOUR TOKEN AT: https://dashboard.ngrok.com/get-started/your-authtoken.\n",
        "\n",
        "\"Show code\" to see output where it will ask for your access token. It is then saved for the instance.\n",
        "\n",
        "You will find your access url at the following link:\n",
        "https://dashboard.ngrok.com/cloud-edge/endpoints"
      ],
      "metadata": {
        "id": "U6Vf4xi_Prtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 - Download Ngrok\n",
        "\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# 3 - setup Ngrok - authtoken\n",
        "\n",
        "#Ask token\n",
        "print(\"Get your authtoken from https://dashboard.ngrok.com/auth\")\n",
        "import getpass\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok http 7860 &')"
      ],
      "metadata": {
        "id": "J_wV7BLpPrGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBPaPdaYOoxx"
      },
      "source": [
        "#Check GPU#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFhrToHEuCgu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOIs6SzoPYMb"
      },
      "source": [
        "#Install Environment and download upscale models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "tHFce7974ZTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/hlky/stable-diffusion\n",
        "!git clone https://github.com/daswer123/stable-diffusion-colab"
      ],
      "metadata": {
        "id": "nK3YkcGEQGvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a904d5be-d93f-486e-8b88-11f6f53bea2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stable-diffusion'...\n",
            "remote: Enumerating objects: 849, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 849 (delta 36), reused 44 (delta 22), pack-reused 785\u001b[K\n",
            "Receiving objects: 100% (849/849), 42.62 MiB | 23.40 MiB/s, done.\n",
            "Resolving deltas: 100% (409/409), done.\n",
            "Cloning into 'stable-diffusion-colab'...\n",
            "remote: Enumerating objects: 844, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 844 (delta 33), reused 42 (delta 21), pack-reused 785\u001b[K\n",
            "Receiving objects: 100% (844/844), 42.62 MiB | 20.35 MiB/s, done.\n",
            "Resolving deltas: 100% (406/406), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-colab\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "XYmzhtTQQHjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "45mEkqD9QKr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_miniconda()"
      ],
      "metadata": {
        "id": "JSzimbTvzfle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env update -n base -f /content/stable-diffusion-colab/environment.yaml"
      ],
      "metadata": {
        "id": "Otu2EscTzmtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-colab/src/gfpgan/\n",
        "!pip install basicsr facexlib yapf lmdb opencv-python pyyaml tb-nightly --no-deps\n",
        "!python setup.py develop\n",
        "!pip install realesrgan\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models"
      ],
      "metadata": {
        "id": "PYdQkr_Byls3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-colab/src/realesrgan/\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P experiments/pretrained_models\n",
        "!wget https://github.com/matomo-org/travis-scripts/blob/master/fonts/Arial.ttf?raw=true -O /content/stable-diffusion/arial.ttf\n",
        "!sudo apt-get install fonts-dejavu\n",
        "!sudo fc-cache"
      ],
      "metadata": {
        "id": "QGvjUoXr3F5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEJI7Vokrldp"
      },
      "source": [
        "#Run Gradio - Main fork - Suggested\n",
        "#Get your url from https://dashboard.ngrok.com/cloud-edge/endpoints or https://dashboard.ngrok.com/tunnels/agents click on the one appearing in the list, and use the https address to access Stable Diffusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XEV3esR49DHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 7860 &')\n",
        "#@markdown ---\n",
        "#@markdown Optimized mode ON / OFF\n",
        "OPTIMIZED = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Optimization Mode: \n",
        "MODE = \"TURBO\" #@param [\"NORMAL\", \"TURBO\"]\n",
        "\n",
        "#@markdown Load Upscalers in RAM\n",
        "CPU = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown do not switch the model to 16-bit floats (might be useful with models loaded to cpu, or optimized modes)\n",
        "NOHALF = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown Show Progress Bars (May help images not loading)\n",
        "PROGRESSBARS = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Use Password (username: webui)\n",
        "PASS = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### Enter Password\n",
        "PW = \"\" #@param {type: 'string'}\n",
        "\n",
        "#@markdown Skip Grid creating\n",
        "SKIPGRID = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### **Config Paths and Optimizations**\n",
        "MODEL_PATH = \"/gdrive/MyDrive/model.ckpt\" #@param {type: 'string'}\n",
        "OUTPUT_DIR = \"/gdrive/MyDrive/GradIO_out/_sd_webui\" #@param {type: 'string'}\n",
        "\n",
        "if OPTIMIZED:\n",
        "  if MODE == 'NORMAL':\n",
        "    op = '--optimized'\n",
        "  elif MODE == 'TURBO':\n",
        "    op = '--optimized-turbo'\n",
        "else:\n",
        "  op = ''\n",
        "\n",
        "if CPU:\n",
        "  op2 = '--extra-models-cpu'\n",
        "else:\n",
        "  op2 = ''\n",
        "\n",
        "if PROGRESSBARS:\n",
        "  op3 = '--no-progressbar-hiding'\n",
        "else:\n",
        "  op3 = ''\n",
        "\n",
        "if SKIPGRID:\n",
        "  op4 = '--skip-grid'\n",
        "else:\n",
        "  op4 = ''\n",
        "\n",
        "if PASS:\n",
        "  op5 = f'--share-password {PW}'\n",
        "else:\n",
        "  op5 = ''\n",
        "\n",
        "if NOHALF:\n",
        "  op6 = '--no-half'\n",
        "else:\n",
        "  op6 = '' \n",
        "\n",
        "STARTPROMPT = f'--ckpt {MODEL_PATH} --outdir {OUTPUT_DIR} --share --gfpgan-dir /content/stable-diffusion-colab/src/gfpgan --realesrgan-dir /content/stable-diffusion-colab/src/realesrgan {op} {op2} {op3} {op4} {op5} {op6}'\n",
        "\n",
        "%cd /content/stable-diffusion/\n",
        "!python3 /content/stable-diffusion/scripts/webui.py {STARTPROMPT}"
      ],
      "metadata": {
        "id": "-mD9n131xNJU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start Experimental Animation GradIO - no promises\n",
        "based on Deforum's notebook:\n",
        "https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb\n",
        "\n",
        "Go to https://dashboard.ngrok.com/cloud-edge/endpoints to see your link to Stable Diffusion Animation Gui, use the https:// one.\n"
      ],
      "metadata": {
        "id": "GDU5-u84vVNF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1b7IvlOqNlt",
        "outputId": "5815d87a-5abf-412f-e9eb-3f777c867cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/stable-diffusion/scripts/gradio_anim_01.py': No such file or directory\n",
            "/content/sdtest\n",
            "Cloning into 'stable-diffusion'...\n",
            "remote: Enumerating objects: 846, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "^C\n",
            "[Errno 2] No such file or directory: '/content/sdtest/stable-diffusion'\n",
            "/content/sdtest\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main_parser.py\", line 8, in <module>\n",
            "    from pip._internal.cli import cmdoptions\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/cmdoptions.py\", line 23, in <module>\n",
            "    from pip._internal.cli.parser import ConfigOptionParser\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/parser.py\", line 12, in <module>\n",
            "    from pip._internal.configuration import Configuration, ConfigurationError\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/configuration.py\", line 21, in <module>\n",
            "    from pip._internal.exceptions import (\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/exceptions.py\", line 8, in <module>\n",
            "    from pip._vendor.requests.models import Request, Response\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/requests/__init__.py\", line 44, in <module>\n",
            "    from pip._vendor import chardet\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/chardet/__init__.py\", line 19, in <module>\n",
            "    from .universaldetector import UniversalDetector\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/chardet/universaldetector.py\", line 47, in <module>\n",
            "    from .mbcsgroupprober import MBCSGroupProber\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/chardet/mbcsgroupprober.py\", line 32, in <module>\n",
            "    from .sjisprober import SJISProber\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/chardet/sjisprober.py\", line 30, in <module>\n",
            "    from .chardistribution import SJISDistributionAnalysis\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/chardet/chardistribution.py\", line 36, in <module>\n",
            "    from .jisfreq import (JIS_CHAR_TO_FREQ_ORDER, JIS_TABLE_SIZE,\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\n",
            "KeyboardInterrupt\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython) (0.7.0)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.1\n",
            "--2022-09-01 10:12:25--  https://raw.githubusercontent.com/XmYx/waifu-diffusion-gradio-hosted-by-colab-en/main/anim/gradio_anim_01.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44065 (43K) [text/plain]\n",
            "Saving to: ‘/content/stable-diffusion/scripts/gradio_anim_01.py’\n",
            "\n",
            "gradio_anim_01.py   100%[===================>]  43.03K  --.-KB/s    in 0.004s  \n",
            "\n",
            "Last-modified header missing -- time-stamps turned off.\n",
            "2022-09-01 10:12:25 (10.7 MB/s) - ‘/content/stable-diffusion/scripts/gradio_anim_01.py’ saved [44065/44065]\n",
            "\n",
            "[Errno 2] No such file or directory: '/content/sdtest/stable-diffusion'\n",
            "/content/sdtest\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion/scripts/gradio_anim_01.py\", line 11, in <module>\n",
            "    import pynvml\n",
            "ModuleNotFoundError: No module named 'pynvml'\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system_raw('./ngrok http 7860 &')\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #### **Config Paths and Optimizations**\n",
        "MODEL_PATH = \"/gdrive/MyDrive/model.ckpt\" #@param {type: 'string'}\n",
        "OUTPUT_DIR = \"/gdrive/MyDrive/GradIO_out/_sd_webui\" #@param {type: 'string'}\n",
        "\n",
        "#@markdown Optimized mode ON / OFF\n",
        "OPTIMIZED = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Optimization Mode: \n",
        "MODE = \"TURBO\" #@param [\"NORMAL\", \"TURBO\"]\n",
        "\n",
        "#@markdown Load Upscalers in RAM\n",
        "CPU = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Show Progress Bars (May help images not loading)\n",
        "PROGRESSBARS = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Skip Grid creating\n",
        "SKIPGRID = False #@param {type:\"boolean\"}\n",
        "#@markdown Use Password\n",
        "PASS = False #@param {type:\"boolean\"}\n",
        "#@markdown #### Enter Password\n",
        "PW = \"bbb\" #@param {type: 'string'}\n",
        "\n",
        "if OPTIMIZED:\n",
        "  if MODE == 'NORMAL':\n",
        "    op = '--optimized'\n",
        "  elif MODE == 'TURBO':\n",
        "    op = '--optimized-turbo'\n",
        "else:\n",
        "  op = ''\n",
        "\n",
        "if CPU:\n",
        "  op2 = '--extra-models-cpu'\n",
        "else:\n",
        "  op2 = ''\n",
        "\n",
        "if PROGRESSBARS:\n",
        "  op3 = '--no-progressbar-hiding'\n",
        "else:\n",
        "  op3 = ''\n",
        "\n",
        "if SKIPGRID:\n",
        "  op4 = '--skip-grid'\n",
        "else:\n",
        "  op4 = ''\n",
        "\n",
        "if PASS:\n",
        "  op5 = f'--share-password {PW}'\n",
        "else:\n",
        "  op5 = ''\n",
        "\n",
        "STARTPROMPT = f'--ckpt {MODEL_PATH} --outdir {OUTPUT_DIR} --share --gfpgan-dir /content/stable-diffusion-colab/src/gfpgan --realesrgan-dir /content/stable-diffusion-colab/src/realesrgan {op} {op2} {op3} {op4} {op5}'\n",
        "\n",
        "!rm /content/stable-diffusion/scripts/gradio_anim_01.py\n",
        "%mkdir /content/sdtest\n",
        "%cd /content/sdtest\n",
        "!git clone https://github.com/deforum/stable-diffusion\n",
        "%cd /content/sdtest/stable-diffusion\n",
        "!pip install -e .\n",
        "!pip install IPython\n",
        "!wget -N https://raw.githubusercontent.com/XmYx/waifu-diffusion-gradio-hosted-by-colab-en/main/anim/gradio_anim_01.py -P /content/stable-diffusion/scripts\n",
        "%cd /content/sdtest/stable-diffusion\n",
        "!python3 /content/stable-diffusion/scripts/gradio_anim_01.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Gradio - HLKY Development Fork"
      ],
      "metadata": {
        "id": "tewliHC0FRPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 7860 &')\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #### **Config Paths and Optimizations**\n",
        "MODEL_PATH = \"/gdrive/MyDrive/model.ckpt\" #@param {type: 'string'}\n",
        "OUTPUT_DIR = \"/gdrive/MyDrive/GradIO_out/_sd_webui\" #@param {type: 'string'}\n",
        "\n",
        "#@markdown Optimized mode ON / OFF\n",
        "OPTIMIZED = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Optimization Mode: \n",
        "MODE = \"TURBO\" #@param [\"NORMAL\", \"TURBO\"]\n",
        "\n",
        "#@markdown Load Upscalers in RAM\n",
        "CPU = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Show Progress Bars (May help images not loading)\n",
        "PROGRESSBARS = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Skip Grid creating\n",
        "SKIPGRID = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if OPTIMIZED:\n",
        "  if MODE == 'NORMAL':\n",
        "    op = '--optimized'\n",
        "  elif MODE == 'TURBO':\n",
        "    op = '--optimized-turbo'\n",
        "else:\n",
        "  op = ''\n",
        "\n",
        "if CPU:\n",
        "  op2 = '--extra-models-cpu'\n",
        "else:\n",
        "  op2 = ''\n",
        "\n",
        "if PROGRESSBARS:\n",
        "  op3 = '--no-progressbar-hiding'\n",
        "else:\n",
        "  op3 = ''\n",
        "\n",
        "if SKIPGRID:\n",
        "  op4 = '--skip-grid'\n",
        "else:\n",
        "  op4 = ''\n",
        "\n",
        "STARTPROMPT = f'--ckpt {MODEL_PATH} --outdir {OUTPUT_DIR} --share --gfpgan-dir /content/stable-diffusion-colab/src/gfpgan --realesrgan-dir /content/stable-diffusion-colab/src/realesrgan {op} {op2} {op3} {op4}'\n",
        "\n",
        "%cd /content/stable-diffusion/\n",
        "!python3 /content/stable-diffusion-webui/scripts/webui.py {STARTPROMPT}"
      ],
      "metadata": {
        "id": "rIPPLW4wFQYA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Gradio - Dasver123's fork"
      ],
      "metadata": {
        "id": "GBpwH5R9Q8rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 7860 &')\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #### **Config Paths and Optimizations**\n",
        "MODEL_PATH = \"/gdrive/MyDrive/model.ckpt\" #@param {type: 'string'}\n",
        "OUTPUT_DIR = \"/gdrive/MyDrive/GradIO_out/_sd_webui\" #@param {type: 'string'}\n",
        "\n",
        "#@markdown Optimized mode ON / OFF\n",
        "OPTIMIZED = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Optimization Mode: \n",
        "MODE = \"TURBO\" #@param [\"NORMAL\", \"TURBO\"]\n",
        "\n",
        "#@markdown Load Upscalers in RAM\n",
        "CPU = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Show Progress Bars (May help images not loading)\n",
        "PROGRESSBARS = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Skip Grid creating\n",
        "SKIPGRID = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if OPTIMIZED:\n",
        "  if MODE == 'NORMAL':\n",
        "    op = '--optimized'\n",
        "  elif MODE == 'TURBO':\n",
        "    op = '--optimized-turbo'\n",
        "else:\n",
        "  op = ''\n",
        "\n",
        "if CPU:\n",
        "  op2 = '--extra-models-cpu'\n",
        "else:\n",
        "  op2 = ''\n",
        "\n",
        "if PROGRESSBARS:\n",
        "  op3 = '--no-progressbar-hiding'\n",
        "else:\n",
        "  op3 = ''\n",
        "\n",
        "if SKIPGRID:\n",
        "  op4 = '--skip-grid'\n",
        "else:\n",
        "  op4 = ''\n",
        "\n",
        "STARTPROMPT = f'--ckpt {MODEL_PATH} --outdir {OUTPUT_DIR} --share --gfpgan-dir /content/stable-diffusion-colab/src/gfpgan --realesrgan-dir /content/stable-diffusion-colab/src/realesrgan {op} {op2} {op3} {op4}'\n",
        "\n",
        "%cd /content/stable-diffusion/\n",
        "!python3 /content/stable-diffusion-colab/scripts/webui.py {STARTPROMPT}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KyAUosxuQ1O5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "GBPaPdaYOoxx",
        "GBpwH5R9Q8rm"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}